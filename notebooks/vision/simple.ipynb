{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../firstcell.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static quantization of a model consists of the following steps:\n",
    "\n",
    "#     Fuse modules\n",
    "#     Insert Quant/DeQuant Stubs\n",
    "#     Prepare the fused module (insert observers before and after layers)\n",
    "#     Calibrate the prepared module (pass it representative data)\n",
    "#     Convert the calibrated module (replace with quantized version)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = \"qnnpack\"  # running on a x86 CPU. Use \"qnnpack\" if running on ARM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (3): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Conv2d(2, 64, 3), nn.ReLU(), nn.Conv2d(64, 128, 3), nn.ReLU())\n",
    "\n",
    "## EAGER MODE\n",
    "m = copy.deepcopy(model)\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): QuantStub(\n",
       "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (1): ConvReLU2d(\n",
       "    (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (2): Identity()\n",
       "  (3): ConvReLU2d(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (4): Identity()\n",
       "  (5): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Fuse\n",
    "- Inplace fusion replaces the first module in the sequence with the fused module, and the rest with identity modules\n",
    "\"\"\"\n",
    "torch.quantization.fuse_modules(\n",
    "    m, [\"0\", \"1\"], inplace=True\n",
    ")  # fuse first Conv-ReLU pair\n",
    "torch.quantization.fuse_modules(\n",
    "    m, [\"2\", \"3\"], inplace=True\n",
    ")  # fuse second Conv-ReLU pair\n",
    "\n",
    "\"\"\"Insert stubs\"\"\"\n",
    "m = nn.Sequential(torch.quantization.QuantStub(), *m, torch.quantization.DeQuantStub())\n",
    "\n",
    "\"\"\"Prepare\"\"\"\n",
    "m.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.quantization.prepare(m, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Didn't find engine for operation quantized::conv2d_prepack NoQEngine",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     m(x)\n\u001b[1;32m      9\u001b[0m \u001b[39m\"\"\"Convert\"\"\"\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m torch\u001b[39m.\u001b[39;49mquantization\u001b[39m.\u001b[39;49mconvert(m, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     12\u001b[0m \u001b[39m\"\"\"Check\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(m[[\u001b[39m1\u001b[39m]]\u001b[39m.\u001b[39mweight()\u001b[39m.\u001b[39melement_size()) \u001b[39m# 1 byte instead of 4 bytes for FP32\u001b[39;00m\n",
      "File \u001b[0;32m~/ghq/github.com/alansynn/deepcrunch3/env/lib/python3.10/site-packages/torch/ao/quantization/quantize.py:551\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inplace:\n\u001b[1;32m    550\u001b[0m     module \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(module)\n\u001b[0;32m--> 551\u001b[0m _convert(\n\u001b[1;32m    552\u001b[0m     module, mapping, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, is_reference\u001b[39m=\u001b[39;49mis_reference,\n\u001b[1;32m    553\u001b[0m     convert_custom_config_dict\u001b[39m=\u001b[39;49mconvert_custom_config_dict)\n\u001b[1;32m    554\u001b[0m \u001b[39mif\u001b[39;00m remove_qconfig:\n\u001b[1;32m    555\u001b[0m     _remove_qconfig(module)\n",
      "File \u001b[0;32m~/ghq/github.com/alansynn/deepcrunch3/env/lib/python3.10/site-packages/torch/ao/quantization/quantize.py:591\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(mod, _FusedModule) \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    588\u001b[0m        type_before_parametrizations(mod) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m custom_module_class_mapping:\n\u001b[1;32m    589\u001b[0m         _convert(mod, mapping, \u001b[39mTrue\u001b[39;00m,  \u001b[39m# inplace\u001b[39;00m\n\u001b[1;32m    590\u001b[0m                  is_reference, convert_custom_config_dict)\n\u001b[0;32m--> 591\u001b[0m     reassign[name] \u001b[39m=\u001b[39m swap_module(mod, mapping, custom_module_class_mapping)\n\u001b[1;32m    593\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m reassign\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    594\u001b[0m     module\u001b[39m.\u001b[39m_modules[key] \u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m~/ghq/github.com/alansynn/deepcrunch3/env/lib/python3.10/site-packages/torch/ao/quantization/quantize.py:624\u001b[0m, in \u001b[0;36mswap_module\u001b[0;34m(mod, mapping, custom_module_class_mapping)\u001b[0m\n\u001b[1;32m    622\u001b[0m         new_mod \u001b[39m=\u001b[39m qmod\u001b[39m.\u001b[39mfrom_float(mod, weight_qparams)\n\u001b[1;32m    623\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 624\u001b[0m         new_mod \u001b[39m=\u001b[39m qmod\u001b[39m.\u001b[39;49mfrom_float(mod)\n\u001b[1;32m    625\u001b[0m     swapped \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m swapped:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# Preserve module's pre forward hooks. They'll be called on quantized input\u001b[39;00m\n",
      "File \u001b[0;32m~/ghq/github.com/alansynn/deepcrunch3/env/lib/python3.10/site-packages/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py:110\u001b[0m, in \u001b[0;36mConvReLU2d.from_float\u001b[0;34m(cls, mod)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(mod) \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mao\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mintrinsic\u001b[39m.\u001b[39mqat\u001b[39m.\u001b[39mConvBnReLU2d:\n\u001b[1;32m    107\u001b[0m     mod\u001b[39m.\u001b[39mweight, mod\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m fuse_conv_bn_weights(\n\u001b[1;32m    108\u001b[0m         mod\u001b[39m.\u001b[39mweight, mod\u001b[39m.\u001b[39mbias, mod\u001b[39m.\u001b[39mbn\u001b[39m.\u001b[39mrunning_mean, mod\u001b[39m.\u001b[39mbn\u001b[39m.\u001b[39mrunning_var,\n\u001b[1;32m    109\u001b[0m         mod\u001b[39m.\u001b[39mbn\u001b[39m.\u001b[39meps, mod\u001b[39m.\u001b[39mbn\u001b[39m.\u001b[39mweight, mod\u001b[39m.\u001b[39mbn\u001b[39m.\u001b[39mbias)\n\u001b[0;32m--> 110\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(ConvReLU2d, \u001b[39mcls\u001b[39;49m)\u001b[39m.\u001b[39;49mfrom_float(mod)\n",
      "File \u001b[0;32m~/ghq/github.com/alansynn/deepcrunch3/env/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/conv.py:480\u001b[0m, in \u001b[0;36mConv2d.from_float\u001b[0;34m(cls, mod)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    473\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_float\u001b[39m(\u001b[39mcls\u001b[39m, mod):\n\u001b[1;32m    474\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Creates a quantized module from a float module or qparams_dict.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \n\u001b[1;32m    476\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39m        mod (Module): a float module, either produced by torch.ao.quantization\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[39m          utilities or provided by the user\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m     \u001b[39mreturn\u001b[39;00m _ConvNd\u001b[39m.\u001b[39;49mfrom_float(\u001b[39mcls\u001b[39;49m, mod)\n",
      "File \u001b[0;32m~/ghq/github.com/alansynn/deepcrunch3/env/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/conv.py:242\u001b[0m, in \u001b[0;36m_ConvNd.from_float\u001b[0;34m(cls, mod)\u001b[0m\n\u001b[1;32m    240\u001b[0m         mod \u001b[39m=\u001b[39m mod[\u001b[39m0\u001b[39m]\n\u001b[1;32m    241\u001b[0m     weight_post_process \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39mqconfig\u001b[39m.\u001b[39mweight()\n\u001b[0;32m--> 242\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_qconv(mod, activation_post_process, weight_post_process)\n",
      "File \u001b[0;32m~/ghq/github.com/alansynn/deepcrunch3/env/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/conv.py:206\u001b[0m, in \u001b[0;36m_ConvNd.get_qconv\u001b[0;34m(cls, mod, activation_post_process, weight_post_process)\u001b[0m\n\u001b[1;32m    204\u001b[0m qweight \u001b[39m=\u001b[39m _quantize_weight(mod\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mfloat(), weight_post_process)\n\u001b[1;32m    205\u001b[0m \u001b[39m# the __init__ call used is the one from derived classes and not the one from _ConvNd\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m qconv \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(mod\u001b[39m.\u001b[39;49min_channels, mod\u001b[39m.\u001b[39;49mout_channels, mod\u001b[39m.\u001b[39;49mkernel_size,\n\u001b[1;32m    207\u001b[0m             mod\u001b[39m.\u001b[39;49mstride, mod\u001b[39m.\u001b[39;49mpadding, mod\u001b[39m.\u001b[39;49mdilation, mod\u001b[39m.\u001b[39;49mgroups,\n\u001b[1;32m    208\u001b[0m             mod\u001b[39m.\u001b[39;49mbias \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, mod\u001b[39m.\u001b[39;49mpadding_mode)\n\u001b[1;32m    209\u001b[0m qconv\u001b[39m.\u001b[39mset_weight_bias(qweight, mod\u001b[39m.\u001b[39mbias)\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m activation_post_process \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m activation_post_process\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mfloat:\n",
      "File \u001b[0;32m~/ghq/github.com/alansynn/deepcrunch3/env/lib/python3.10/site-packages/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py:84\u001b[0m, in \u001b[0;36mConvReLU2d.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, in_channels, out_channels, kernel_size, stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     82\u001b[0m              padding\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, dilation\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, groups\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, bias\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     83\u001b[0m              padding_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 84\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     85\u001b[0m         in_channels, out_channels, kernel_size, stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m     86\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding, dilation\u001b[39m=\u001b[39;49mdilation, groups\u001b[39m=\u001b[39;49mgroups, bias\u001b[39m=\u001b[39;49mbias,\n\u001b[1;32m     87\u001b[0m         padding_mode\u001b[39m=\u001b[39;49mpadding_mode, device\u001b[39m=\u001b[39;49mdevice, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/ghq/github.com/alansynn/deepcrunch3/env/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/conv.py:436\u001b[0m, in \u001b[0;36mConv2d.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    433\u001b[0m dilation \u001b[39m=\u001b[39m _pair(dilation)\n\u001b[1;32m    434\u001b[0m \u001b[39m# Subclasses of _ConvNd need to call _init rather than __init__. See\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m# discussion on PR #49702\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_init(\n\u001b[1;32m    437\u001b[0m     in_channels, out_channels, kernel_size, stride, padding, dilation,\n\u001b[1;32m    438\u001b[0m     \u001b[39mFalse\u001b[39;49;00m, _pair(\u001b[39m0\u001b[39;49m), groups, bias, padding_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs)\n",
      "File \u001b[0;32m~/ghq/github.com/alansynn/deepcrunch3/env/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/conv.py:82\u001b[0m, in \u001b[0;36m_ConvNd._init\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m     74\u001b[0m qweight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_empty_affine_quantized(\n\u001b[1;32m     75\u001b[0m     weight_shape \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kernel_size),\n\u001b[1;32m     76\u001b[0m     scale\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, zero_point\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mqint8,\n\u001b[1;32m     77\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m factory_kwargs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[1;32m     78\u001b[0m bias_float \u001b[39m=\u001b[39m (\n\u001b[1;32m     79\u001b[0m     torch\u001b[39m.\u001b[39mzeros(out_channels, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat,\n\u001b[1;32m     80\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m factory_kwargs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m}) \u001b[39mif\u001b[39;00m bias \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 82\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_weight_bias(qweight, bias_float)\n\u001b[1;32m     83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzero_point \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/ghq/github.com/alansynn/deepcrunch3/env/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/conv.py:445\u001b[0m, in \u001b[0;36mConv2d.set_weight_bias\u001b[0;34m(self, w, b)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_weight_bias\u001b[39m(\u001b[39mself\u001b[39m, w: torch\u001b[39m.\u001b[39mTensor, b: Optional[torch\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 445\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_packed_params \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mquantized\u001b[39m.\u001b[39;49mconv2d_prepack(\n\u001b[1;32m    446\u001b[0m             w, b, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n\u001b[1;32m    447\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_packed_params \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mquantized\u001b[39m.\u001b[39mconv2d_prepack(\n\u001b[1;32m    449\u001b[0m             w, b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n",
      "File \u001b[0;32m~/ghq/github.com/alansynn/deepcrunch3/env/lib/python3.10/site-packages/torch/_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    498\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Didn't find engine for operation quantized::conv2d_prepack NoQEngine"
     ]
    }
   ],
   "source": [
    "\"\"\"Calibrate\n",
    "- This example uses random data for convenience. Use representative (validation) data instead.\n",
    "\"\"\"\n",
    "with torch.inference_mode():\n",
    "    for _ in range(10):\n",
    "        x = torch.rand(1, 2, 28, 28)\n",
    "        m(x)\n",
    "\n",
    "\"\"\"Convert\"\"\"\n",
    "torch.quantization.convert(m, inplace=True)\n",
    "\n",
    "\"\"\"Check\"\"\"\n",
    "print(m[[1]].weight().element_size())  # 1 byte instead of 4 bytes for FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FX GRAPH\n",
    "from torch.quantization import quantize_fx\n",
    "\n",
    "m = copy.deepcopy(model)\n",
    "m.eval()\n",
    "qconfig_dict = {\"\": torch.quantization.get_default_qconfig(backend)}\n",
    "# Prepare\n",
    "model_prepared = quantize_fx.prepare_fx(m, qconfig_dict)\n",
    "# Calibrate - Use representative (validation) data.\n",
    "with torch.inference_mode():\n",
    "    for _ in range(10):\n",
    "        x = torch.rand(1, 2, 28, 28)\n",
    "        model_prepared(x)\n",
    "# quantize\n",
    "model_quantized = quantize_fx.convert_fx(model_prepared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
