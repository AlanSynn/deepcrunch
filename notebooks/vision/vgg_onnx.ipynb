{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../first.cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp32 = \"./vgg16-12.onnx\"\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataloader\n",
    "val_dataset = datasets.CIFAR10(\"./data\",\n",
    "                             train=False,\n",
    "                             download=True)\n",
    "val_dataloader = Dataloader(\n",
    "                     val_dataset,\n",
    "                     batch_size=32, shuffle=False,\n",
    "                     ping_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepcrunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = deepcrunch.quantize(model_fp32, output_path=\"./vgg16_quantize_nc.onnx\", val_dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If calibration or accuracy aware needed\n",
    "eval_func = # Some function that takes in a model and returns accuracy or metrics. Usually a validation function.\n",
    "\n",
    "quantized_model = deepcrunch.quantize(model_fp32, output_path=\"./vgg16_quantize_nc.onnx\", val_dataset=val_dataset, eval_func=eval_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model_size = deepcrunch.performance.size_in_mb(\n",
    "    \"./vgg16-12.onnx\", human_readable=True\n",
    ")\n",
    "\n",
    "quantized_model_size = deepcrunch.performance.size_in_mb(\n",
    "    \"./vgg16_quantize_nc.onnx\", human_readable=True\n",
    ")\n",
    "\n",
    "print(f\"Original model size: {original_model_size}\")\n",
    "print(f\"Quantized model size: {quantized_model_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "device_id = 0\n",
    "print(ort.get_device()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = [(\n",
    "    \"CUDAExecutionProvider\", \n",
    "    { \n",
    "        \"device_id\": device_id,\n",
    "        \"cudnn_conv_algo_search\": \"HEURISTIC\", \n",
    "        \"do_copy_in_default_stream\": True\n",
    "    }\n",
    ")]\n",
    "\n",
    "opts = ort.SessionOptions()\n",
    "opts.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "opts.enable_cpu_mem_arena = False\n",
    "opts.enable_mem_pattern = False\n",
    "opts.enable_mem_reuse = False\n",
    "\n",
    "opts.intra_op_num_threads = 1 \n",
    "opts.inter_op_num_threads = 1\n",
    "\n",
    "sess = ort.InferenceSession(\n",
    "    \"vgg16_quantize_nc.onnx\", \n",
    "    sess_options=opts, \n",
    "    providers=providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcrunch.performance.model_latency import do_inference\n",
    "\n",
    "do_inference(\"vgg16-12.onnx\", \"VGG16-12\", input_dim=(1, 3, 224, 224), providers=providers)\n",
    "do_inference(\"vgg16_float16.onnx\", \"Float16\", input_dim=(1, 3, 224, 224), providers=providers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
