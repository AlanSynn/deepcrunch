{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration dataloader\n",
    "class CalibDataLoader(object):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.sequence = \"Seoul is a beautiful city!\"\n",
    "        self.encoded_input = self.tokenizer(self.sequence, return_tensors=\"pt\")\n",
    "        self.label = 1  # negative sentence: 0; positive sentence: 1\n",
    "        self.batch_size = 1\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield self.encoded_input, self.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def eval_func(model):\n",
    "    output = model(**calib_dataloader.encoded_input)\n",
    "    print(\"Output: \", output.logits.detach().numpy())\n",
    "    emotion_type = np.argmax(output.logits.detach().numpy())\n",
    "    return 1 if emotion_type == calib_dataloader.label else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable quantization\n",
    "from neural_compressor.experimental import Quantization\n",
    "\n",
    "quantizer = Quantization(\"./config.yaml\")\n",
    "quantizer.model = model\n",
    "quantizer.calib_dataloader = CalibDataLoader()\n",
    "quantizer.eval_func = eval_func\n",
    "q_model = quantizer.fit()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
