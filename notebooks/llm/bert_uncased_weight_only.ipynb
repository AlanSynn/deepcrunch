{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "# %load ../firstcell.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForSequenceClassification, AutoTokenizer\n",
      "File \u001b[0;32m~/projects/deepcrunch/env/lib/python3.10/site-packages/torch/__init__.py:1187\u001b[0m\n\u001b[1;32m   1180\u001b[0m         __all__\u001b[39m.\u001b[39mappend(name)\n\u001b[1;32m   1182\u001b[0m \u001b[39m################################################################################\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[39m# Import interface functions defined in Python\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[39m################################################################################\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m \n\u001b[1;32m   1186\u001b[0m \u001b[39m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[39;00m\n\u001b[0;32m-> 1187\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[39m################################################################################\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Remove unnecessary members\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39m################################################################################\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[39mdel\u001b[39;00m _StorageBase\n",
      "File \u001b[0;32m~/projects/deepcrunch/env/lib/python3.10/site-packages/torch/functional.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m _add_docstr\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mopt_einsum\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mopt_einsum\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_lowrank\u001b[39;00m \u001b[39mimport\u001b[39;00m svd_lowrank, pca_lowrank\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39moverrides\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n\u001b[1;32m     12\u001b[0m     handle_torch_function)\n",
      "File \u001b[0;32m~/projects/deepcrunch/env/lib/python3.10/site-packages/torch/nn/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparameter\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     Parameter \u001b[39mas\u001b[39;00m Parameter,\n\u001b[1;32m      4\u001b[0m     UninitializedParameter \u001b[39mas\u001b[39;00m UninitializedParameter,\n\u001b[1;32m      5\u001b[0m     UninitializedBuffer \u001b[39mas\u001b[39;00m UninitializedBuffer,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparallel\u001b[39;00m \u001b[39mimport\u001b[39;00m DataParallel \u001b[39mas\u001b[39;00m DataParallel\n",
      "File \u001b[0;32m~/projects/deepcrunch/env/lib/python3.10/site-packages/torch/nn/modules/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39minstancenorm\u001b[39;00m \u001b[39mimport\u001b[39;00m InstanceNorm1d, InstanceNorm2d, InstanceNorm3d, \\\n\u001b[1;32m     21\u001b[0m     LazyInstanceNorm1d, LazyInstanceNorm2d, LazyInstanceNorm3d\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnormalization\u001b[39;00m \u001b[39mimport\u001b[39;00m LocalResponseNorm, CrossMapLRN2d, LayerNorm, GroupNorm\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdropout\u001b[39;00m \u001b[39mimport\u001b[39;00m Dropout, Dropout1d, Dropout2d, Dropout3d, AlphaDropout, FeatureAlphaDropout\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpadding\u001b[39;00m \u001b[39mimport\u001b[39;00m ReflectionPad1d, ReflectionPad2d, ReflectionPad3d, ReplicationPad1d, ReplicationPad2d, \\\n\u001b[1;32m     25\u001b[0m     ReplicationPad3d, ZeroPad2d, ConstantPad1d, ConstantPad2d, ConstantPad3d\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m Embedding, EmbeddingBag\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1002\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1411\u001b[0m, in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1577\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:161\u001b[0m, in \u001b[0;36m_path_isfile\u001b[0;34m(path)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:153\u001b[0m, in \u001b[0;36m_path_is_mode_type\u001b[0;34m(path, mode)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration dataloader\n",
    "class CalibDataLoader(object):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.sequence = \"Seoul is a beautiful city!\"\n",
    "        self.encoded_input = self.tokenizer(self.sequence, return_tensors=\"pt\")\n",
    "        self.label = 1  # negative sentence: 0; positive sentence: 1\n",
    "        self.batch_size = 1\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield self.encoded_input, self.label\n",
    "\n",
    "\n",
    "calib_data_loader = CalibDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def eval_func(model):\n",
    "    output = model(**calib_dataloader.encoded_input)\n",
    "    print(\"Output: \", output.logits.detach().numpy())\n",
    "    emotion_type = np.argmax(output.logits.detach().numpy())\n",
    "    return 1 if emotion_type == calib_dataloader.label else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable quantization\n",
    "from neural_compressor.experimental import Quantization\n",
    "\n",
    "quantizer = Quantization(\"./config.yml\")\n",
    "quantizer.model = model\n",
    "quantizer.calib_dataloader = CalibDataLoader()\n",
    "quantizer.eval_func = eval_func\n",
    "q_model = quantizer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
